# AI-Powered Micro-Service Log Analytics for Proactive System Insights


1.Introduction:
Microservice architecture has revolutionized the way modern software applications are designed and deployed. It involves breaking down a monolithic application into a suite of smaller, independent services, each running in its own process and communicating through lightweight mechanisms. While microservices offer advantages in terms of scalability and agility, they also introduce challenges related to monitoring and maintaining the health of a large number of distributed services.
In industrial microservice systems, these challenges are magnified, with dozens to thousands of services running on different machines. Failures can occur due to various reasons, including infrastructure issues, hardware failures, improper configurations, implementation faults, and incorrect coordination in service interactions. Given the dynamic and uncertain nature of these environments, it is imperative to detect anomalies in real-time to enable engineers to react promptly and ensure the reliability and performance of the system.
To address these challenges, this project proposes the development of DeepMicroLog, a cutting-edge microservice anomaly detection system that leverages deep learning techniques. Inspired by the DeepTraLog approach, DeepMicroLog combines distributed tracing and logging data to create a unified graph-based representation of microservice behavior. This approach allows us to capture the intricate relationships and behaviors within microservice systems and automatically detect anomalies at runtime.

2.Business Problem:
In the realm of existing log anomaly detection systems within microservices environments, a set of formidable challenges arises due to the intricate nature of microservices architecture. These systems grapple with the overwhelming volume of log data generated by numerous microservices instances, often encountering scalability and performance bottlenecks. Distributed log collection poses a significant hurdle, as capturing logs from dispersed services across different nodes and containers can be inefficient. The variability in log formats employed by diverse microservices presents yet another challenge, with existing systems struggling to adapt to the ever-changing log structures. Achieving real-time log analysis without introducing latency remains a complex endeavor, hindering the timely response to anomalies or issues. To correlate logs across microservices and trace transactions, context preservation is vital, necessitating precise timestamps and trace identifiers. Moreover, ensuring the accurate identification of anomalies within the intricate interactions of microservices is a persistent challenge. Resource allocation for log anomaly detection requires a delicate balance between computational efficiency and minimal impact on the microservices themselves. Efficiently managing log data, especially in long-term storage, is a recurring concern, along with the need for robust privacy and security measures when handling potentially sensitive information within logs. Seamlessly integrating log anomaly detection into the microservices ecosystem, implementing effective alerting mechanisms, and facilitating historical log analysis further complicate the landscape. Tackling these challenges necessitates specialized solutions tailored to the unique demands of the microservices environment, emphasizing scalability, log format adaptability, real-time analysis, efficient resource usage, data security, and seamless integration.

   3. Project:
3.1 Current product in the market
Currently there are many products available in the market for general log analysis anf anomaly detection.
Splunk: Splunk is a widely used commercial log analysis platform that provides a range of features for collecting, indexing, searching, and analyzing log data. It offers powerful search capabilities, real-time monitoring, visualization, and machine learning-driven insights.
Graylog: Graylog is an open-source log management platform that allows you to collect, index, and analyze log data. It offers features like centralized logging, real-time search, alerting, and customizable dashboards.
Datadog: Datadog is a monitoring and analytics platform that includes log management capabilities. It allows you to collect, search, and analyze log data along with metrics and traces for a holistic view of your application's performance.
New Relic Logs: New Relic offers log management and analysis as part of its observability platform. It helps you correlate logs with metrics and traces to troubleshoot and optimize your applications.
As mentioned above all of these products focus on log visualization and most of the products are proprietary and too expensive to afford for any small scale industry. These are focusing to give solutions to single service based anomaly detection and fails to consider the whole microservice environment on trace and log events.
3.2 Proposed System: 3.2.1. Objectives:
• Collecting the log events and trace events ( from the logs) and parsing them into a common format
• Generating the event embedding vector and Trace Event Graph( TEG) for numerical representation of the trace and log events
• Training the models ( Classification tree and KNN) using the event embedding vector and TEG
• Detecting anomalies using the model for future logs and visualization of the log anomalies.
 
   3.2.2. Scope:
The scope of our project encompasses the following pivotal components:
● Data Generation : Using the Train Ticket Booking application with 41 microservices for generation of log files using manual testing , selenium testing , performance testing tool ( JMeter) approaches.
○ Detailed Testing scenarios mentioned in data section of this proposal.
● Data cleaning and parsing : The log files will be parsed using Logstash Grok filter and common
format log events and trace events.
● Model Training : Using the log events and trace events from the previous step we will create event embedding vectors and TEG. Using these Event embedding and TEG combination of classification and regression models along with KNN will be used to create the anomaly detection system.
● Visualization Tool Incorporation: Using the ELK stack , The future logs are stored in the elastic will be pulled using API for anomaly detection using the model and will be reported back to the Kibana dashboard for root cause analysis.
○ Root Cause Analysis – This feature is highlighting / suggesting potential root cause of any failure requests across all microservices.
  
